{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Localiza cada moeda, extraindo da imagem um array com cada uma das localizações\n",
    "#### 2 - em cada recorte da imagem original, transforma em B&W, escala o recorte e extrai as features\n",
    "#### 3 - passa cada um dos recortes para as MLP's e armazena o resultado de cada imagem\n",
    "#### 4 - Avalia as probabilidades de cada resultado e informa o resultado com maior probabilidade como resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from minisom import MiniSom\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from skimage.color import rgb2gray\n",
    "from joblib import dump, load\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "path_images = 'coin_images/train/5-c/'\n",
    "coin_img = '1-c_2002_10.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    # Função para criar descritores de imagens utilizando HOG\n",
    "    def create_features(self, image_str_img):\n",
    "        \n",
    "        # Se a entrada é uma string, assumimos que é um nome de arquivo\n",
    "        if isinstance(image_str_img, str):\n",
    "            # Carrega a imagem\n",
    "            image = imread(image_str_img)\n",
    "            try:\n",
    "                # Carrega a imagem\n",
    "                image = imread(image_str_img)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Arquivo {image_str_img} não encontrado.\")\n",
    "                return None\n",
    "            except OSError:\n",
    "                print(f\"Erro ao ler o arquivo {image_str_img}.\")\n",
    "                return None\n",
    "            # Caso contrário, assumimos que é uma imagem\n",
    "        else:\n",
    "            image = image_str_img\n",
    "\n",
    "        # Se a imagem não for em escala de cinza, converte para escala de cinza\n",
    "        if len(image.shape) > 2:\n",
    "            image = rgb2gray(image)\n",
    "\n",
    "        # Redimensiona a imagem para um tamanho fixo\n",
    "        image = resize(image, self.size)\n",
    "\n",
    "        # Calcula o descritor HOG para a imagem\n",
    "        fd = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=False)\n",
    "\n",
    "        return fd\n",
    "\n",
    "    # Função para processar imagens em um diretório e extrair características\n",
    "    def process_images(self, dir_name):\n",
    "        features_dict = {}\n",
    "\n",
    "        # Para cada arquivo no diretório\n",
    "        for file_name in os.listdir(dir_name):\n",
    "\n",
    "            # Se o arquivo for uma imagem\n",
    "            if (file_name.endswith('.png') or file_name.endswith('.jpg')):\n",
    "\n",
    "                # Extrai características da imagem\n",
    "                features = self.create_features(dir_name + file_name)\n",
    "\n",
    "                # Se houve um erro na leitura da imagem, continue para a próxima\n",
    "                if features is None:\n",
    "                    continue\n",
    "\n",
    "                # Armazena as características no dicionário com o nome do arquivo como a chave\n",
    "                features_dict[file_name] = features\n",
    "                \n",
    "        return features_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelData:\n",
    "    def __init__(self, name, path, path_sufix='', test_size=0.2, image_size=(64, 64)) -> None:\n",
    "        self.name = name\n",
    "        self.path = path\n",
    "        self.path_sufix = path_sufix\n",
    "        self.test_size = test_size\n",
    "        self.classifier = None\n",
    "        self.imageProcessor = ImageProcessor(image_size)\n",
    "        self.__create_model_data()\n",
    "\n",
    "    def __create_model_data(self):\n",
    "        features = []\n",
    "        labels = []\n",
    "\n",
    "        for label in ['1-r', '5-c', '10-c', '25-c', '50-c']:\n",
    "            temp_path = os.path.join(self.path, label, self.path_sufix)\n",
    "            print(temp_path)\n",
    "            \n",
    "            features_dict = self.imageProcessor.process_images(temp_path)\n",
    "            temp_labels = (len(features_dict.keys()) * (' ' + label)).strip().split(' ')\n",
    "            # Converte o dicionário de características para uma lista, mantendo a mesma ordem dos rótulos.\n",
    "            temp_features = [features_dict[file_name] for file_name in sorted(features_dict.keys())]\n",
    "\n",
    "            features.extend(temp_features)\n",
    "            labels.extend(temp_labels)\n",
    "\n",
    "        self.features_train, self.features_test, self.labels_train, self.labels_test = train_test_split(features, labels, test_size=self.test_size, random_state=42)\n",
    "\n",
    "    def train_classifier(self, load_model = False):\n",
    "        # Cria o classificador SVM\n",
    "        if load_model:\n",
    "            clf = load(f'svm_model_{self.name}.joblib')\n",
    "        else:\n",
    "            print(f'Creating classifier... {self.name}')\n",
    "            clf = svm.SVC(gamma='scale')\n",
    "            # Treina o classificador SVM\n",
    "            print('Training classifier...')\n",
    "            clf.fit(self.features_train, self.labels_train)\n",
    "            # Salva o modelo\n",
    "            dump(clf, f'svm_model_{self.name}.joblib')\n",
    "\n",
    "        # Testa o classificador\n",
    "        labels_pred = clf.predict(self.features_test)\n",
    "\n",
    "        # Calcula a precisão do classificador\n",
    "        accuracy = sum(self.labels_test == labels_pred) / len(self.labels_test)\n",
    "        print('Acurácia:', accuracy)\n",
    "        self.classifier = clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialize as listas para armazenar as características e os rótulos\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Para cada diretório na pasta atual\n",
    "for dir_name in [path_images]:#os.listdir('.'):\n",
    "    if os.path.isdir(dir_name):\n",
    "\n",
    "        # Para cada arquivo no diretório\n",
    "        for file_name in os.listdir(dir_name):\n",
    "\n",
    "            # Se o arquivo for uma imagem\n",
    "            if (file_name.endswith('.png') or file_name.endswith('.jpg')) and file_name.endswith('_gs.jpg'):\n",
    "\n",
    "                # Carregue a imagem em escala de cinza\n",
    "                img_path = os.path.join(dir_name, file_name)\n",
    "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Redimensione a imagem para 64x64 pixels\n",
    "                image_resized = cv2.resize(image, (128, 128))\n",
    "\n",
    "                # Achate a imagem em um vetor\n",
    "                feature = image_resized.flatten()\n",
    "\n",
    "                # Normalize as características para terem uma média de 0 e um desvio padrão de 1\n",
    "                feature = (feature - np.mean(feature)) / np.std(feature)\n",
    "\n",
    "                # Adicione as características e o rótulo às suas respectivas listas\n",
    "                features.append(feature)\n",
    "                labels.append(dir_name)  # assumindo que o nome do diretório é o rótulo\n",
    "\n",
    "# Converta as listas em arrays numpy\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialize um dicionário para armazenar os SOMs e seus rótulos\n",
    "soms = {}\n",
    "som_labels = {}\n",
    "neurons = 50\n",
    "\n",
    "# Obtenha os valores únicos de moedas\n",
    "coin_values = np.unique(labels)\n",
    "\n",
    "# Para cada valor de moeda\n",
    "for value in coin_values:\n",
    "\n",
    "    # Crie um novo SOM\n",
    "    som = MiniSom(x=neurons, y=neurons, input_len=features.shape[1])\n",
    "\n",
    "    # Treine o SOM com as características das moedas desse valor\n",
    "    som.train_random(features[labels == value], num_iteration=5000)\n",
    "\n",
    "    # Armazene o SOM\n",
    "    soms[value] = som\n",
    "\n",
    "    # Inicialize uma matriz para armazenar os rótulos do SOM\n",
    "    som_labels[value] = np.empty((neurons, neurons), dtype=str)  # Mude para dtype=str\n",
    "\n",
    "    # Para cada neurônio no SOM\n",
    "    for i in range(neurons):\n",
    "        for j in range(neurons):\n",
    "\n",
    "            # Encontre as características que são mais semelhantes a esse neurônio\n",
    "            min_dist = np.inf\n",
    "            min_label = None\n",
    "            for k, feature in enumerate(features[labels == value]):\n",
    "                dist = np.linalg.norm(som.get_weights()[i, j] - feature)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    min_label = labels[labels == value][k]\n",
    "\n",
    "            # Rotule o neurônio com a classe de moeda mais comum entre as características mais semelhantes\n",
    "            som_labels[value][i, j] = min_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialize uma matriz para armazenar os rótulos do SOM\n",
    "som_labels[value] = np.empty((neurons, neurons), dtype=str)  # Mude para dtype=str\n",
    "\n",
    "# Para cada neurônio no SOM\n",
    "for i in range(neurons):\n",
    "    for j in range(neurons):\n",
    "\n",
    "        # Encontre as características que são mais semelhantes a esse neurônio\n",
    "        min_dist = np.inf\n",
    "        min_label = None\n",
    "        for k, feature in enumerate(features[labels == value]):\n",
    "            dist = np.linalg.norm(som.get_weights()[i, j] - feature)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                min_label = labels[labels == value][k]\n",
    "\n",
    "        # Rotule o neurônio com a classe de moeda mais comum entre as características mais semelhantes\n",
    "        som_labels[value][i, j] = min_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_coin(image, soms, som_labels):\n",
    "    # Redimensione a imagem para 64x64 pixels\n",
    "    image_resized = cv2.resize(image, (128, 128))\n",
    "\n",
    "    # Achate a imagem em um vetor\n",
    "    feature = image_resized.flatten()\n",
    "\n",
    "    # Normalize as características para terem uma média de 0 e um desvio padrão de 1\n",
    "    feature = (feature - np.mean(feature)) / np.std(feature)\n",
    "\n",
    "    # Inicialize uma variável para armazenar a menor distância e a classe correspondente\n",
    "    min_dist = np.inf\n",
    "    min_class = None\n",
    "\n",
    "    # Para cada SOM\n",
    "    for value, som in soms.items():\n",
    "\n",
    "        # Encontre o neurônio mais semelhante\n",
    "        winner = som.winner(feature)\n",
    "\n",
    "        # Calcule a distância entre a característica e o neurônio vencedor\n",
    "        dist = np.linalg.norm(som.get_weights()[winner] - feature)\n",
    "\n",
    "\n",
    "        # Se a distância for menor que a menor distância encontrada até agora\n",
    "        if dist < min_dist:\n",
    "\n",
    "            # Atualize a menor distância e a classe correspondente\n",
    "            min_dist = dist\n",
    "            min_class = som_labels[value][winner]\n",
    "\n",
    "    # Retorne a classe com a menor distância\n",
    "    return min_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_coin(cv2.imread(path_images + coin_img, cv2.IMREAD_GRAYSCALE), soms, som_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_coin(cv2.imread('coin_images/train/1-c/1-c_1994_4_rot90.jpg', cv2.IMREAD_GRAYSCALE), soms, som_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_coin(cv2.imread('coin_images/train/5-c/5-c_2009_17.jpg', cv2.IMREAD_GRAYSCALE), soms, som_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coin_images/train/1-r\\\n",
      "coin_images/train/5-c\\\n",
      "coin_images/train/10-c\\\n",
      "coin_images/train/25-c\\\n",
      "coin_images/train/50-c\\\n",
      "coin_images/train/1-r\\\n",
      "coin_images/train/5-c\\\n",
      "coin_images/train/10-c\\\n",
      "coin_images/train/25-c\\\n",
      "coin_images/train/50-c\\\n",
      "coin_images/train/1-r\\\n",
      "coin_images/train/5-c\\\n",
      "coin_images/train/10-c\\\n",
      "coin_images/train/25-c\\\n",
      "coin_images/train/50-c\\\n"
     ]
    }
   ],
   "source": [
    "#Cria os dados para treinamento e teste do modelo com variacoes no tamanho da imagem para o hog descriptor\n",
    "#coinsData_64 = ModelData('coins_64', 'coin_images/train/', '', 0.2, (64, 64))\n",
    "coinsData_128 = ModelData('coins_128', 'coin_images/train/', '', 0.2, (128, 128))\n",
    "coinsData_256 = ModelData('coins_256', 'coin_images/train/', '', 0.2, (256, 256))\n",
    "coinsData_512 = ModelData('coins_512', 'coin_images/train/', '', 0.2, (512, 512))\n",
    "#bwData_64 = ModelData('coins_bw_64', 'coin_images/train/', 'bw/', 0.2, (64, 64))\n",
    "#bwData_128 = ModelData('coins_bw_128', 'coin_images/train/', 'bw/', 0.2, (128, 128))\n",
    "#bwData_256 = ModelData('coins_bw_256', 'coin_images/train/', 'bw/', 0.2, (256, 256))\n",
    "\n",
    "#modelData_lst = [coinsData_64, coinsData_128, coinsData_256, bwData_64, bwData_128, bwData_256]\n",
    "modelData_lst = [coinsData_128, coinsData_256, coinsData_512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model coins_128\n",
      "Creating classifier... coins_128\n",
      "Training classifier...\n",
      "Acurácia: 0.8805309734513275\n",
      "\n",
      "Training model coins_256\n",
      "Creating classifier... coins_256\n",
      "Training classifier...\n",
      "Acurácia: 0.9424778761061947\n",
      "\n",
      "Training model coins_512\n",
      "Creating classifier... coins_512\n",
      "Training classifier...\n",
      "Acurácia: 0.9336283185840708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for modelData in modelData_lst:\n",
    "    print(f'Training model {modelData.name}')\n",
    "    modelData.train_classifier()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_coins(image, classifier, image_processor):\n",
    "    # Converte a imagem para escala de cinza\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Suaviza a imagem\n",
    "    #gray = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    # Detecta círculos na imagem\n",
    "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 60, param1=150, param2=250, minRadius=0, maxRadius=0)\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "    else:\n",
    "        circles = []\n",
    "\n",
    "    coinCount = 0\n",
    "    for i in circles[0,:]:\n",
    "        # Verifica se o círculo está dentro dos limites da imagem\n",
    "        if i[0]-i[2] >= 0 and i[1]-i[2] >= 0 and i[0]+i[2] <= gray.shape[1] and i[1]+i[2] <= gray.shape[0]:\n",
    "            # Obtém a região de interesse da imagem\n",
    "            roi = gray[i[1]-i[2]:i[1]+i[2], i[0]-i[2]:i[0]+i[2]]\n",
    "\n",
    "            # Verifica se a ROI não está vazia\n",
    "            if roi.size > 0:\n",
    "                # Redimensiona a região de interesse para o tamanho esperado pelo classificador\n",
    "                roi = cv2.resize(roi, image_processor.size)\n",
    "                #cv2.imshow('Coins', image)\n",
    "                #print(\"ROI: \", roi)\n",
    "                \n",
    "                # Extrai as características da região de interesse\n",
    "                features = image_processor.create_features(roi)\n",
    "\n",
    "                #print(\"Features: \", features)\n",
    "\n",
    "                # Classifica a região de interesse\n",
    "                label = classifier.predict([features])\n",
    "\n",
    "                # Desenha o círculo na imagem\n",
    "                cv2.circle(image, (i[0], i[1]), i[2], (0, 0, 255), 2)\n",
    "\n",
    "                # Desenha o rótulo na imagem\n",
    "                cv2.rectangle(image, (i[0] - 30 , i[1] - 25), (i[0] + 25, i[1] + 1), (171, 219, 227), cv2.FILLED)\n",
    "                cv2.putText(image, label[0].replace('-',''), (i[0] - 20, i[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (168, 129, 50), 1, cv2.LINE_AA, False)\n",
    "                \n",
    "\n",
    "                # Incrementa o contador de moedas\n",
    "                coinCount += 1\n",
    "    \n",
    "\n",
    "        # Desenha o contador de moedas na imagem\n",
    "    textSize, _ = cv2.getTextSize(f'Total de moedas: {coinCount}', cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "    textX = image.shape[1] - textSize[0] - 20\n",
    "    textY = image.shape[0] - 20\n",
    "    \n",
    "    cv2.rectangle(image, (textX - 8, textY - textSize[1] - 8), (textX + textSize[0] + 8, textY + 8), (171, 219, 227), cv2.FILLED)\n",
    "    cv2.putText(image, f'Total de moedas: {coinCount}', (textX, textY), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (168, 129, 50), 1, cv2.LINE_AA, False)\n",
    "\n",
    "    # Mostra a imagem\n",
    "    cv2.imshow('Detected Coins', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega a imagem\n",
    "image = cv2.imread('coin_images/test/test_3.jpg')\n",
    "\n",
    "# Carrega o classificador SVM\n",
    "classifier = coinsData_512.classifier\n",
    "\n",
    "# Cria o processador de imagem\n",
    "image_processor = coinsData_512.imageProcessor\n",
    "\n",
    "# Detecta as moedas na imagem\n",
    "detect_coins(image, classifier, image_processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9646017699115044\n"
     ]
    }
   ],
   "source": [
    "# Cria o classificador MLP. \n",
    "# A lista [64, 64] define duas camadas ocultas com 64 neurônios cada.\n",
    "# A função de ativação 'relu' é a função padrão.\n",
    "# A taxa máxima de iterações (max_iter) é definida como 2000.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=[128, 1024, 64], activation='logistic', max_iter=10000)\n",
    "\n",
    "# Treina o classificador MLP.\n",
    "mlp.fit(coinsData_256.features_train, coinsData_256.labels_train)\n",
    "print(mlp.score(coinsData_256.features_test, coinsData_256.labels_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Faz a previsão para uma nova instância.\n",
    "#prediction = mlp.predict([new_instance])\n",
    "image = cv2.imread('coin_images/test/test_3.jpg')\n",
    "detect_coins(image, mlp, coinsData_256.imageProcessor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
