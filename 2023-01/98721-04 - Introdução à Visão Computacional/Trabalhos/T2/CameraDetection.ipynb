{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'J:/Disco/Camera/192.168.0.211_80/2023/06/25/'\n",
    "files = ['rec_2023_06_25_12_14_29.mp4', 'rec_2023_06_25_12_14_48.mp4', 'rec_2023_06_25_12_15_20.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(video_path, frame_number):\n",
    "    capture = cv.VideoCapture(video_path)\n",
    "    capture.set(1, frame_number)\n",
    "    ret, frame = capture.read()\n",
    "    capture.release()\n",
    "    return frame\n",
    "\n",
    "def get_frames(video_path, frame_numbers):\n",
    "    frames = []\n",
    "    for frame_number in frame_numbers:\n",
    "        frames.append(get_frame(video_path, frame_number))\n",
    "    return frames\n",
    "\n",
    "def get_number_of_frames(video_path):\n",
    "    capture = cv.VideoCapture(video_path)\n",
    "    num_frames = int(capture.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    capture.release()\n",
    "    return num_frames\n",
    "\n",
    "def get_all_frames(video_path):\n",
    "    frames = []\n",
    "    frame_count = get_number_of_frames(video_path)\n",
    "    for frame_number in range(frame_count):\n",
    "        frames.append(get_frame(video_path, frame_number))\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_filter(img):\n",
    "    # Perform the 2-D fast Fourier Transform on the image\n",
    "    f = np.fft.fft2(img)\n",
    "\n",
    "    # Shift the zero-frequency component to the center of the spectrum\n",
    "    fshift = np.fft.fftshift(f)\n",
    "\n",
    "    # Create a mask with the same size as the image that is True for the frequencies you want to keep\n",
    "    mask = np.zeros_like(img, dtype=bool)\n",
    "    mask[img.shape[0]//2-150:img.shape[0]//2+150, img.shape[1]//2-150:img.shape[1]//2+150] = True\n",
    "\n",
    "    # Apply the mask to the frequency-domain image\n",
    "    fshift_masked = fshift * mask\n",
    "\n",
    "    # Shift the zero-frequency component back to the top left corner\n",
    "    f_ishift = np.fft.ifftshift(fshift_masked)\n",
    "\n",
    "    # Perform the inverse 2-D fast Fourier Transform\n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "\n",
    "    # Take only the real part of the result\n",
    "    img_back = np.abs(img_back)\n",
    "\n",
    "    return img_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(video_path):\n",
    "    capture = cv.VideoCapture(video_path)\n",
    "\n",
    "    # Get the framerate\n",
    "    fps = capture.get(cv.CAP_PROP_FPS)\n",
    "\n",
    "    # Calculate the frame delay (in milliseconds)\n",
    "    frame_delay = int(1000 / fps)\n",
    "    area_threshold = 50\n",
    "    object_detector = cv.createBackgroundSubtractorMOG2(history=150, varThreshold=20)\n",
    "\n",
    "    # Show video\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "\n",
    "        # If frame is read correctly, ret is True\n",
    "        if not ret:\n",
    "            # If we've reached the end of the video (or there's an error), start it over\n",
    "            capture.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "            continue\n",
    "        \n",
    "        # Apply filtering\n",
    "        frame_f = frequency_filter(frame)\n",
    "        #print(frame_f.shape)\n",
    "        #print(frame.shape)\n",
    "\n",
    "        # Detect objects\n",
    "        mask = object_detector.apply(frame_f)\n",
    "        _, mask = cv.threshold(mask, 50, 255, cv.THRESH_BINARY)\n",
    "        contours, _ = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            area = cv.contourArea(cnt)\n",
    "            if area > area_threshold:\n",
    "                #cv.drawContours(frame, [cnt], -1, (0, 255, 0), 2)\n",
    "                x,y,w,h = cv.boundingRect(cnt)\n",
    "                cv.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 1)\n",
    "\n",
    "        cv.imshow('frame', frame)\n",
    "        cv.imshow('mask', mask)\n",
    "        cv.imshow('filtered', frame_f)\n",
    "        if cv.waitKey(frame_delay) & 0xFF == ord('q'):  # wait for frame_delay ms; break if 'q' is pressed\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(frame, threshold_value=127, max_value=255):\n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding\n",
    "    _, thresholded_frame = cv.threshold(gray_frame, threshold_value, max_value, cv.THRESH_BINARY)\n",
    "\n",
    "    return thresholded_frame\n",
    "\n",
    "def play_video_with_thresholding(video_path, threshold_value=127, max_value=255):\n",
    "    # Open the video file\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # If the frame was read correctly ret is True\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply thresholding to the frame\n",
    "        thresholded_frame = apply_threshold(frame, threshold_value, max_value)\n",
    "\n",
    "        # Display the thresholded frame\n",
    "        cv.imshow('frame', thresholded_frame)\n",
    "\n",
    "        # Wait for 25 ms before moving on to the next frame\n",
    "        # This will slow down the video\n",
    "        cv.waitKey(25)\n",
    "\n",
    "    # Release the video file\n",
    "    cap.release()\n",
    "\n",
    "    # Close all OpenCV windows\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directional_filter(image, angle):\n",
    "    # Create a directional filter mask\n",
    "    mask = np.ones(image.shape, dtype=bool)\n",
    "    mask = ndimage.rotate(mask, angle, reshape=False)\n",
    "\n",
    "    # Apply the mask to the image\n",
    "    filtered_image = image * mask\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def play_video_with_directional_filtering(video_path, angle):\n",
    "    # Open the video file\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # If the frame was read correctly ret is True\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply directional filtering to the frame\n",
    "        filtered_frame = directional_filter(frame, angle)\n",
    "\n",
    "        # Display the filtered frame\n",
    "        cv.imshow('frame', filtered_frame)\n",
    "\n",
    "        # Wait for 25 ms before moving on to the next frame\n",
    "        # This will slow down the video\n",
    "        cv.waitKey(25)\n",
    "\n",
    "    # Release the video file\n",
    "    cap.release()\n",
    "\n",
    "    # Close all OpenCV windows\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def remove_lines(frame, threshold=200, min_line_length=100, max_line_gap=10):\n",
    "    # Convert the frame to grayscale\n",
    "    #gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply edge detection\n",
    "    edges = cv.Canny(frame, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Detect lines using the Hough transform\n",
    "    lines = cv.HoughLinesP(edges, 1, np.pi/180, threshold, minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "\n",
    "    # If lines were found\n",
    "    if lines is not None:\n",
    "        # Draw black lines on the original frame\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv.line(frame, (x1, y1), (x2, y2), (0, 0, 0), 2)\n",
    "\n",
    "    return frame\n",
    "'''\n",
    "def remove_lines(frame, threshold=200, min_line_length=100, max_line_gap=10):\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply edge detection\n",
    "    edges = cv.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Detect lines using the Hough transform\n",
    "    lines = cv.HoughLinesP(edges, 1, np.pi/180, threshold, minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "\n",
    "    # Create an empty mask to draw the lines on\n",
    "    mask = np.zeros_like(frame)\n",
    "\n",
    "    # If lines were found\n",
    "    if lines is not None:\n",
    "        # Draw white lines on the mask\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv.line(mask, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "\n",
    "    # Inpaint the original frame using the mask\n",
    "    frame_inpaint = cv.inpaint(frame, cv.cvtColor(mask, cv.COLOR_BGR2GRAY), 3, cv.INPAINT_TELEA)\n",
    "\n",
    "    return frame_inpaint\n",
    "\n",
    "\n",
    "def play_video_with_line_removal(video_path, threshold_lines=200, min_line_length=100, max_line_gap=10, threshold_value=127):\n",
    "    # Open the video file\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # If the frame was read correctly ret is True\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Remove lines from the frame\n",
    "        #frame = apply_threshold(frame, threshold_value)\n",
    "        frame_without_lines = remove_lines(frame, threshold_lines, min_line_length, max_line_gap)\n",
    "\n",
    "        # Display the frame without lines\n",
    "        cv.imshow('frame', frame_without_lines)\n",
    "\n",
    "        # Wait for 25 ms before moving on to the next frame\n",
    "        # This will slow down the video\n",
    "        cv.waitKey(25)\n",
    "\n",
    "    # Release the video file\n",
    "    cap.release()\n",
    "\n",
    "    # Close all OpenCV windows\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video_with_line_removal(path + files[0], 50, 120, 10, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video_with_directional_filtering(path + files[0], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video_with_thresholding(path + files[0], 180, 205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(path + files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_frames(path + files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = get_frame(path + files[0], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv.imshow('frame', frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
