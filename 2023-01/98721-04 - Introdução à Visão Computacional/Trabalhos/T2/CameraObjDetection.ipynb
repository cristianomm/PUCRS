{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3c3ddd3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "from scipy.spatial import distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "221ec17e",
      "metadata": {},
      "outputs": [],
      "source": [
        "yolov = 'yolov4'\n",
        "model_path = 'C:/Users/crist/GitHub/darknet/'\n",
        "#model_path = 'C:/Users/10087940/Documents/GitHub/darknet/'\n",
        "\n",
        "#path = 'C:/Temp/videos/'\n",
        "path = 'J:/Disco/Camera/192.168.0.211_80/2023/06/25/'\n",
        "files = ['rec_2023_06_25_12_14_29.mp4', 'rec_2023_06_25_12_14_48.mp4', 'rec_2023_06_25_12_15_20.mp4']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "79d60c8a-91dd-4f87-9ee5-94a695786ed2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-25T19:31:55.645030+00:00",
          "start_time": "2023-06-25T19:31:53.211835+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "257717640"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# dowload dos pesos\n",
        "#!git clone https://github.com/AlexeyAB/darknet.git\n",
        "'''\n",
        "import requests\n",
        "\n",
        "url = f'https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/{yolov}.weights'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open(f'{model_path}{yolov}.weights', 'wb').write(r.content)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8d8bcf1e-b99d-4e20-911c-6b545fb9e50c",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "class ObjectFeatures:\n",
        "    def __init__(self, id, name, class_id, features):\n",
        "        self.id = id\n",
        "        self.name = name\n",
        "        self.class_id = class_id\n",
        "        self.features = features\n",
        "\n",
        "class ObjectDetector:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.objects = []\n",
        "        self.net, self.output_layers = self.load_yolo()\n",
        "        self.classes = self.load_classes()\n",
        "        self.colors = np.random.uniform(0, 255, size=(len(self.classes), 3))\n",
        "\n",
        "    def load_yolo(self):\n",
        "        net = cv2.dnn.readNet(f'{model_path}{yolov}.weights', f'{model_path}cfg/{yolov}.cfg')\n",
        "        layer_names = net.getLayerNames()\n",
        "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "        return net, output_layers\n",
        "    \n",
        "    def load_classes(self):\n",
        "        classes = []\n",
        "        with open(f'{model_path}/cfg/coco.names', 'r') as f:\n",
        "            classes = [line.strip() for line in f.readlines()]\n",
        "        return classes\n",
        "    \n",
        "    def detect_objects(self, img):\n",
        "    \n",
        "        outs, height, width = None, None, None\n",
        "\n",
        "        if img is not None:\n",
        "            height, width, channels = img.shape\n",
        "            blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "            self.net.setInput(blob)\n",
        "            outs = self.net.forward(self.output_layers)\n",
        "\n",
        "        return outs, height, width\n",
        "    \n",
        "    def get_box_dimensions(self, outs, height, width):\n",
        "    \n",
        "        if outs is None or height is None or width is None:\n",
        "            return None, None, None\n",
        "        \n",
        "        class_ids = []\n",
        "        confidences = []\n",
        "        boxes = []\n",
        "        for out in outs:\n",
        "            for detection in out:\n",
        "                scores = detection[5:]\n",
        "                class_id = np.argmax(scores)\n",
        "                confidence = scores[class_id]\n",
        "                if confidence > 0.5:\n",
        "                    # Object detected\n",
        "                    center_x = int(detection[0] * width)\n",
        "                    center_y = int(detection[1] * height)\n",
        "                    w = int(detection[2] * width)\n",
        "                    h = int(detection[3] * height)\n",
        "\n",
        "                    x = int(center_x - w / 2)\n",
        "                    y = int(center_y - h / 2)\n",
        "\n",
        "                    boxes.append([x, y, w, h])\n",
        "                    confidences.append(float(confidence))\n",
        "                    class_ids.append(class_id)\n",
        "\n",
        "        return boxes, confidences, class_ids\n",
        "\n",
        "    def draw_labels(self, boxes, confidences, colors, class_ids, img):\n",
        "\n",
        "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "        font = cv2.FONT_HERSHEY_PLAIN\n",
        "        for i in range(len(boxes)):\n",
        "            if i in indexes:\n",
        "                x, y, w, h = boxes[i]\n",
        "                label = str(self.classes[class_ids[i]])\n",
        "                color = colors[i]\n",
        "                cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
        "                cv2.putText(img, label, (x, y - 5), font, 1, color, 1)\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def print_info(self, frame_id, frame, starting_time):\n",
        "        elapsed_time = time.time() - starting_time\n",
        "        fps = frame_id / elapsed_time\n",
        "        cv2.putText(frame, 'FPS: ' + str(round(fps, 2)), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 0, 150), 2)\n",
        "        cv2.imshow('Image', frame)\n",
        "\n",
        "    def compute_objects(self, boxes, frame, confidences, class_ids):\n",
        "        temp_objects = []\n",
        "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "        for i in range(len(boxes)):\n",
        "            if i in indexes:\n",
        "                x, y, w, h = boxes[i]\n",
        "                label = str(self.classes[class_ids[i]])\n",
        "                roi = frame[y:y+h, x:x+w]\n",
        "                if roi.size > 0:\n",
        "                    features = self.create_features(roi, label)\n",
        "                    temp_objects.append(ObjectFeatures(len(self.objects)+1, label, class_ids[i], features))\n",
        "\n",
        "        # Caso nao tenha detectado nada, inicializa a lista de objetos detectados\n",
        "        if len(self.objects) == 0:\n",
        "            self.objects = temp_objects\n",
        "        #verifica se algum dos objetos detectados já foi detectado anteriormente utilizando \n",
        "        #a distancia do cosseno entre as features\n",
        "        else:\n",
        "            for obj in temp_objects:\n",
        "                measure = -2\n",
        "                for i in range(len(self.objects)):\n",
        "                    # Compara apenas objetos do mesmo tipo...\n",
        "                    #print(f'Comparando {obj.name} com {self.objects[i].name}')\n",
        "                    if(self.objects[i].class_id == obj.class_id):\n",
        "                        measure = distance.cosine(self.objects[i].features, obj.features)\n",
        "                        print(f'Comparing {obj.name} - {obj.id} and {self.objects[i].name} - {self.objects[i].id}')\n",
        "                        print(f'value: {measure}\\n')\n",
        "                        \n",
        "                        # Se a distancia do cosseno for menor que 0.3, considera que é o mesmo objeto\n",
        "                        if measure > 0.3:\n",
        "                            self.objects.append(obj)\n",
        "                            break\n",
        "\n",
        "                # Adiciona na lista caso nao tenha encontrado nenhum objeto parecido\n",
        "                if measure == -2:\n",
        "                    self.objects.append(obj)\n",
        "    \n",
        "    def create_features(self, roi, class_name):\n",
        "        \n",
        "        cv2.imshow(class_name + \"1\", roi)\n",
        "\n",
        "        if len(roi.shape) > 2:\n",
        "            roi = rgb2gray(roi)\n",
        "\n",
        "        # Redimensiona a imagem para um tamanho fixo\n",
        "        if class_name == 'person':\n",
        "            #print('person', roi.shape)\n",
        "            roi = resize(roi, (80, 20))\n",
        "        else:\n",
        "            #print('car', roi.shape)\n",
        "            roi = resize(roi, (40, 80))\n",
        "\n",
        "        # Mostra o roi\n",
        "        cv2.imshow(class_name, roi)\n",
        "\n",
        "        # Calcula o descritor HOG para a imagem\n",
        "        fd = hog(roi, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(1, 1), visualize=False)\n",
        "        #print(class_name, fd)\n",
        "        return fd\n",
        "    \n",
        "    def object_detection_video(self, video_path):\n",
        "        \n",
        "        capture = cv2.VideoCapture(video_path)\n",
        "        ret, frame = capture.read()\n",
        "\n",
        "        # Initialization\n",
        "        frame_id = 0\n",
        "        frame_counter = 0\n",
        "        starting_time = time.time()\n",
        "        fps = capture.get(cv2.CAP_PROP_FPS)\n",
        "        frame_delay = int(1000 / fps)\n",
        "\n",
        "        while True:\n",
        "            ret, frame = capture.read()\n",
        "            frame_id += 1\n",
        "\n",
        "            # Verifica se deve reiniciar o video\n",
        "            if not ret:\n",
        "                print('Restarting...')\n",
        "                print(f'Detected objects: {len(self.objects)}')\n",
        "                capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "                frame_id = 0\n",
        "                starting_time = time.time()\n",
        "                self.objects = []\n",
        "                continue\n",
        "\n",
        "            if frame is not None:\n",
        "                # A cada 5 frames realiza a deteccao de objetos\n",
        "                if frame_counter % 1 == 0:\n",
        "                    # Detecta objetos\n",
        "                    outs, height, width = self.detect_objects(frame)\n",
        "                    boxes, confidences, class_ids = self.get_box_dimensions(outs, height, width)\n",
        "\n",
        "                    # Desenha as caixas verifica os objetos detectados\n",
        "                    if boxes is not None and confidences is not None and class_ids is not None:\n",
        "                        colors = np.random.uniform(0, 255, size=(len(boxes), 2))\n",
        "                        frame = self.draw_labels(boxes, confidences, colors, class_ids, frame)\n",
        "                        self.compute_objects(boxes, frame, confidences, class_ids)\n",
        "\n",
        "                # Mostra informações na tela\n",
        "                self.print_info(frame_id, frame, starting_time)\n",
        "\n",
        "            frame_counter += 1\n",
        "            \n",
        "            if cv2.waitKey(frame_delay) & 0xFF == ord('q'): \n",
        "                print('Quitting...')\n",
        "                print(f'Detected objects: {len(self.objects)}')\n",
        "                break\n",
        "\n",
        "        capture.release()\n",
        "        cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1b39cc40-13c5-480e-9dfa-34061a25f874",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparing car - 2 and car - 1\n",
            "value: 0.12371176455724886\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.1987854560281811\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2052012626643538\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.1892285735261191\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.21949170387135986\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.24534645127055632\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2031399316321958\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.17773912600923936\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.1963785238234521\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2463274216857816\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2355905074493282\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2516383766146557\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2834133509219319\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.23685867677561512\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.27286500714423656\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2459534789501343\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.29270475027629417\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.28426645812906415\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2726062398830571\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.27047350248611535\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2772619837446586\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2683629665615731\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.24138102824973284\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2085494385576756\n",
            "\n",
            "Comparing car - 2 and car - 1\n",
            "value: 0.2468516447599265\n",
            "\n",
            "Comparing person - 3 and person - 2\n",
            "value: 0.10978249507501603\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.2541725643015166\n",
            "\n",
            "Comparing person - 3 and person - 2\n",
            "value: 0.09903723198121606\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.2583966401045854\n",
            "\n",
            "Comparing person - 3 and person - 2\n",
            "value: 0.09876143379205593\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.21663086490403338\n",
            "\n",
            "Comparing person - 3 and person - 2\n",
            "value: 0.13417425547548145\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.2194189128230989\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.20624689262968943\n",
            "\n",
            "Comparing person - 3 and person - 2\n",
            "value: 0.12147436715385995\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.24665487706241762\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.21217445897983533\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.20206348094360937\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.20973192940635121\n",
            "\n",
            "Comparing person - 3 and person - 2\n",
            "value: 0.10937115972509226\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.23278805682274506\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.24006447095974137\n",
            "\n",
            "Comparing person - 3 and person - 2\n",
            "value: 0.13905385135214288\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.26951004495227615\n",
            "\n",
            "Comparing person - 3 and person - 2\n",
            "value: 0.14576016778799428\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.2518798293032546\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.29369178693876485\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.2509812580727294\n",
            "\n",
            "Comparing person - 3 and person - 2\n",
            "value: 0.14933201135262686\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.22498911713741143\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.23036786376742735\n",
            "\n",
            "Comparing car - 3 and car - 1\n",
            "value: 0.20912496232644706\n",
            "\n",
            "Quitting...\n",
            "Detected objects: 2\n"
          ]
        }
      ],
      "source": [
        "objDetector = ObjectDetector()\n",
        "\n",
        "objDetector.object_detection_video(path + files[0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "noteable": {
      "last_delta_id": "ea65cd7f-6d60-4912-8384-81fc1d0a888a",
      "last_transaction_id": "f09a25ab-41ab-4820-8f10-77b184c64975"
    },
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "affc0ebc-1619-5873-b635-88c90284b9ab",
        "openai_ephemeral_user_id": "4001a14c-ee74-5c88-9daf-1e9ddc6940f8",
        "openai_subdivision1_iso_code": "BR-RS"
      }
    },
    "nteract": {
      "version": "noteable@2.9.0"
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
