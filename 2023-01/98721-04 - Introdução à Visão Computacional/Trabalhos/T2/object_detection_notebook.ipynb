{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3c3ddd3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "from scipy.spatial import distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "221ec17e",
      "metadata": {},
      "outputs": [],
      "source": [
        "yolov = 'yolov4'\n",
        "model_path = 'C:/Users/crist/GitHub/darknet/'\n",
        "\n",
        "path = 'J:/Disco/Camera/192.168.0.211_80/2023/06/25/'\n",
        "files = ['rec_2023_06_25_12_14_29.mp4', 'rec_2023_06_25_12_14_48.mp4', 'rec_2023_06_25_12_15_20.mp4', 'rec_2023_06_25_18_23_39']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de7453e-e029-4549-834a-8ca2aa4dae86",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-25T19:26:16.666545+00:00",
          "start_time": "2023-06-25T19:26:13.621594+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69a5948-ca07-471d-9b21-822e4dea259b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-25T19:26:45.401449+00:00",
          "start_time": "2023-06-25T19:26:43.288705+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79d60c8a-91dd-4f87-9ee5-94a695786ed2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-25T19:31:55.645030+00:00",
          "start_time": "2023-06-25T19:31:53.211835+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "#!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
        "\n",
        "import requests\n",
        "\n",
        "url = f'https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/{yolov}.weights'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open(f'{model_path}{yolov}.weights', 'wb').write(r.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8d8bcf1e-b99d-4e20-911c-6b545fb9e50c",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "class ObjectFeatures:\n",
        "    def __init__(self, id, name, class_id, features):\n",
        "        self.id = id\n",
        "        self.name = name\n",
        "        self.class_id = class_id\n",
        "        self.features = features\n",
        "\n",
        "class ObjectDetector:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.objects = []\n",
        "        self.net, self.output_layers = self.load_yolo()\n",
        "        self.classes = self.load_classes()\n",
        "        self.colors = np.random.uniform(0, 255, size=(len(self.classes), 3))\n",
        "\n",
        "    def load_yolo(self):\n",
        "        # Load Yolo\n",
        "        net = cv2.dnn.readNet(f'{model_path}{yolov}.weights', f'{model_path}cfg/{yolov}.cfg')\n",
        "        layer_names = net.getLayerNames()\n",
        "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "        return net, output_layers\n",
        "    \n",
        "    def load_classes(self):\n",
        "        # Load Yolo Classes\n",
        "        classes = []\n",
        "        with open(f'{model_path}/cfg/coco.names', 'r') as f:\n",
        "            classes = [line.strip() for line in f.readlines()]\n",
        "        return classes\n",
        "    \n",
        "    def detect_objects(self, img):\n",
        "    \n",
        "        outs, height, width = None, None, None\n",
        "\n",
        "        if img is not None:\n",
        "            # Size of the image\n",
        "            height, width, channels = img.shape\n",
        "\n",
        "            # Detecting objects\n",
        "            blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "            self.net.setInput(blob)\n",
        "            outs = self.net.forward(self.output_layers)\n",
        "\n",
        "        return outs, height, width\n",
        "    \n",
        "    def get_box_dimensions(self, outs, height, width):\n",
        "    \n",
        "        if outs is None or height is None or width is None:\n",
        "            return None, None, None\n",
        "        \n",
        "        class_ids = []\n",
        "        confidences = []\n",
        "        boxes = []\n",
        "        for out in outs:\n",
        "            for detection in out:\n",
        "                scores = detection[5:]\n",
        "                class_id = np.argmax(scores)\n",
        "                confidence = scores[class_id]\n",
        "                if confidence > 0.5:\n",
        "                    # Object detected\n",
        "                    center_x = int(detection[0] * width)\n",
        "                    center_y = int(detection[1] * height)\n",
        "                    w = int(detection[2] * width)\n",
        "                    h = int(detection[3] * height)\n",
        "\n",
        "                    # Rectangle coordinates\n",
        "                    x = int(center_x - w / 2)\n",
        "                    y = int(center_y - h / 2)\n",
        "\n",
        "                    boxes.append([x, y, w, h])\n",
        "                    confidences.append(float(confidence))\n",
        "                    class_ids.append(class_id)\n",
        "\n",
        "        return boxes, confidences, class_ids\n",
        "\n",
        "    def draw_labels(self, boxes, confidences, colors, class_ids, img):\n",
        "\n",
        "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "        font = cv2.FONT_HERSHEY_PLAIN\n",
        "        for i in range(len(boxes)):\n",
        "            if i in indexes:\n",
        "                x, y, w, h = boxes[i]\n",
        "                label = str(self.classes[class_ids[i]])\n",
        "                color = colors[i]\n",
        "                cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
        "                cv2.putText(img, label, (x, y - 5), font, 1, color, 1)\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def print_info(self, frame_id, frame, starting_time):\n",
        "        elapsed_time = time.time() - starting_time\n",
        "        fps = frame_id / elapsed_time\n",
        "        cv2.putText(frame, 'FPS: ' + str(round(fps, 2)), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 0, 150), 2)\n",
        "        cv2.imshow('Image', frame)\n",
        "\n",
        "    def compute_objects(self, boxes, frame, confidences, class_ids):\n",
        "        temp_objects = []\n",
        "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "        for i in range(len(boxes)):\n",
        "            if i in indexes:\n",
        "                x, y, w, h = boxes[i]\n",
        "                label = str(self.classes[class_ids[i]])\n",
        "                roi = frame[y:y+h, x:x+w]\n",
        "                if roi.size > 0:\n",
        "                    features = self.create_features(roi, label)\n",
        "                    temp_objects.append(ObjectFeatures(len(self.objects)+1, label, class_ids[i], features))\n",
        "\n",
        "        # Caso nao tenha detectado nada, inicializa a lista de objetos detectados\n",
        "        if len(self.objects) == 0:\n",
        "            self.objects = temp_objects\n",
        "        #verifica se algum dos objetos detectados já foi detectado anteriormente utilizando \n",
        "        #a distancia do cosseno entre as features\n",
        "        else:\n",
        "            for obj in temp_objects:\n",
        "                measure = -2\n",
        "                for i in range(len(self.objects)):\n",
        "                    # Compara apenas objetos do mesmo tipo...\n",
        "                    #print(f'Comparando {obj.name} com {self.objects[i].name}')\n",
        "                    if(self.objects[i].class_id == obj.class_id):\n",
        "                        measure = distance.cosine(self.objects[i].features, obj.features)\n",
        "                        print(f'Comparing {obj.name} - {self.objects[i].id} and {self.objects[i].name} - {self.objects[i].id}')\n",
        "                        print(f'value: {measure}')\n",
        "                        \n",
        "                        # Se a distancia do cosseno for menor que 0.25, considera que é o mesmo objeto\n",
        "                        if measure > 0.25:\n",
        "                            self.objects.append(obj)\n",
        "                            break\n",
        "\n",
        "                # Adiciona na lista caso nao tenha encontrado nenhum objeto parecido\n",
        "                if measure == -2:\n",
        "                    self.objects.append(obj)\n",
        "    \n",
        "    def create_features(self, roi, class_name):\n",
        "        # Se a imagem não for em escala de cinza, converte para escala de cinza\n",
        "        if len(roi.shape) > 2:\n",
        "            roi = rgb2gray(roi)\n",
        "\n",
        "        # Redimensiona a imagem para um tamanho fixo\n",
        "        if class_name == 'person':\n",
        "            #print('person', roi.shape)\n",
        "            roi = resize(roi, (80, 20))\n",
        "        else:\n",
        "            #print('car', roi.shape)\n",
        "            roi = resize(roi, (40, 80))\n",
        "\n",
        "        # Calcula o descritor HOG para a imagem\n",
        "        fd = hog(roi, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(1, 1), visualize=False)\n",
        "\n",
        "        return fd\n",
        "    \n",
        "    def object_detection_video(self, video_path):\n",
        "        # Loading image\n",
        "        capture = cv2.VideoCapture(video_path)\n",
        "        ret, frame = capture.read()\n",
        "\n",
        "        # Initialization\n",
        "        frame_id = 0\n",
        "        starting_time = time.time()\n",
        "        # Get the framerate\n",
        "        fps = capture.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        # Calculate the frame delay (in milliseconds)\n",
        "        frame_delay = int(1000 / fps)\n",
        "\n",
        "        # Initialize frame counter\n",
        "        frame_counter = 0\n",
        "\n",
        "        # Initialize trackers list\n",
        "        trackers = []\n",
        "        paths = []\n",
        "\n",
        "        while True:\n",
        "            ret, frame = capture.read()\n",
        "            frame_id += 1\n",
        "\n",
        "            # If frame is read correctly, ret is True\n",
        "            if not ret:\n",
        "                # If we've reached the end of the video (or there's an error), start it over\n",
        "                capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "                frame_id = 0\n",
        "                starting_time = time.time()\n",
        "                trackers = []\n",
        "                paths = []\n",
        "                continue\n",
        "\n",
        "            if frame is not None:\n",
        "                # Every 10 frames, run object detection\n",
        "                if frame_counter % 5 == 0:\n",
        "                    # Detecting objects\n",
        "                    outs, height, width = self.detect_objects(frame)\n",
        "\n",
        "                    # Getting object dimensions\n",
        "                    boxes, confidences, class_ids = self.get_box_dimensions(outs, height, width)\n",
        "\n",
        "                    # Drawing bounding boxes\n",
        "                    if boxes is not None and confidences is not None and class_ids is not None:\n",
        "                        colors = np.random.uniform(0, 255, size=(len(boxes), 2))\n",
        "                        frame = self.draw_labels(boxes, confidences, colors, class_ids, frame)\n",
        "                        self.compute_objects(boxes, frame, confidences, class_ids)\n",
        "\n",
        "                        # Create a tracker for each bounding box\n",
        "                        trackers = [cv2.TrackerMIL_create() for _ in boxes]\n",
        "\n",
        "                        # Initialize each tracker with the current frame and corresponding bounding box\n",
        "                        for tracker, bbox in zip(trackers, boxes):\n",
        "                            ok = tracker.init(frame, bbox)\n",
        "\n",
        "                        # Initialize the path of each object\n",
        "                        # Initialize paths for each object\n",
        "                        paths = [[(bbox[0] + bbox[2] / 2, bbox[1] + bbox[3] / 2)] for bbox in boxes]\n",
        "\n",
        "\n",
        "                else:\n",
        "                    # Update each tracker with the new frame\n",
        "                    for i, tracker in enumerate(trackers):\n",
        "                        ok, bbox = tracker.update(frame)\n",
        "                        # Now bbox contains the new bounding box for the object, and ok is a boolean\n",
        "                        # indicating whether the tracking was successful.\n",
        "                        if ok:\n",
        "                            # Update the path of the object\n",
        "                            paths[i].append((int(bbox[0] + bbox[2] / 2), int(bbox[1] + bbox[3] / 2)))\n",
        "\n",
        "                            # Draw the path of the object\n",
        "                            if len(paths[i]) > 1:\n",
        "                                cv2.line(frame, tuple(map(int, paths[i][-2])), tuple(map(int, paths[i][-1])), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "                # Showing informations on the screen\n",
        "                self.print_info(frame_id, frame, starting_time)\n",
        "\n",
        "            # Increment frame counter\n",
        "            frame_counter += 1\n",
        "            \n",
        "            if cv2.waitKey(frame_delay) & 0xFF == ord('q'): \n",
        "                print('Quitting...')\n",
        "                print(f'Detected objects: {len(self.objects)}')\n",
        "                break\n",
        "\n",
        "        capture.release()\n",
        "        cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1b39cc40-13c5-480e-9dfa-34061a25f874",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparando car - 2 com car - 2\n",
            "medida: 0.19406814249445037\n",
            "Comparando person - 1 com person - 1\n",
            "medida: 0.12019417039878666\n",
            "Comparando person - 1 com person - 1\n",
            "medida: 0.20019308468703767\n",
            "Comparando car - 2 com car - 2\n",
            "medida: 0.2538265101066638\n",
            "Comparando person - 1 com person - 1\n",
            "medida: 0.154654675590973\n",
            "Comparando person - 1 com person - 1\n",
            "medida: 0.14574839490299552\n",
            "Comparando car - 2 com car - 2\n",
            "medida: 0.24310859028093035\n",
            "Comparando car - 3 com car - 3\n",
            "medida: 0.2393227169225477\n",
            "Comparando person - 1 com person - 1\n",
            "medida: 0.16770818370332008\n",
            "Comparando car - 2 com car - 2\n",
            "medida: 0.22218547620134266\n",
            "Comparando car - 3 com car - 3\n",
            "medida: 0.20886550828465733\n",
            "Quitting...\n",
            "Detected objects: 3\n"
          ]
        }
      ],
      "source": [
        "objDetector = ObjectDetector()\n",
        "\n",
        "objDetector.object_detection_video(path + files[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28893a0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(cv2.getBuildInformation())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "noteable": {
      "last_delta_id": "ea65cd7f-6d60-4912-8384-81fc1d0a888a",
      "last_transaction_id": "f09a25ab-41ab-4820-8f10-77b184c64975"
    },
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "affc0ebc-1619-5873-b635-88c90284b9ab",
        "openai_ephemeral_user_id": "4001a14c-ee74-5c88-9daf-1e9ddc6940f8",
        "openai_subdivision1_iso_code": "BR-RS"
      }
    },
    "nteract": {
      "version": "noteable@2.9.0"
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
