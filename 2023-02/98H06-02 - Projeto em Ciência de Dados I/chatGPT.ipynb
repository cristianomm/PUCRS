{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (0.28.0)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.5.1-cp310-cp310-win_amd64.whl (759 kB)\n",
      "     ------------------------------------ 759.8/759.8 kB 448.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from openai==0.28) (4.66.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from openai==0.28) (2.28.2)\n",
      "Requirement already satisfied: aiohttp in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from openai==0.28) (3.9.0)\n",
      "Collecting regex>=2022.1.18\n",
      "  Using cached regex-2023.10.3-cp310-cp310-win_amd64.whl (269 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from requests>=2.20->openai==0.28) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from requests>=2.20->openai==0.28) (1.26.15)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from aiohttp->openai==0.28) (1.9.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\programs\\anaconda3\\envs\\ivc\\lib\\site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\10087940\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.10.3 tiktoken-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28 tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import openai\n",
    "import tiktoken\n",
    "import utils\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "api_key = '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'\n",
    "\n",
    "openai.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_hf = 'hf-KEY'\n",
    "path='D:/Disco/Data/huggingface/'\n",
    "reviews_path = 'C:/Disco/Data/datasets/amazon_us_reviews/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-32k-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-32k-0613\",\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    def __init__(self) -> None:\n",
    "        self.reviews = []\n",
    "\n",
    "    def load_reviews(self, file_name):\n",
    "        self.reviews = pd.read_parquet(reviews_path + file_name)\n",
    "\n",
    "    def get_reviews_by_product_and_category(self, product, category):\n",
    "        return self.reviews[(self.reviews['product_category'] == category) & (self.reviews['product_title'] == product)]\n",
    "\n",
    "    def get_prompt(self, product):\n",
    "        return f\"Please analyze the provided reviews of the product '{product}'. \\n  \\\n",
    "        Create a concise summary that encapsulates the key opinions and sentiments expressed in these reviews. \\n \\\n",
    "        The summary should be structured as if it's a single comprehensive review of the product. \\n \\\n",
    "        The summary should mimic the style and tone of a customer reviews, making it relatable and genuine. \\n \\\n",
    "        Also, provide a list of 5 tags that represent what the customers are saying about the product, give the balance between positive and negative aspects about the product, the tags have this format: #TagName. \\\n",
    "        Format your response as follows: \\n \\\n",
    "            Product: {product}\\n \\\n",
    "            Summary: [Your summary here]\\n \\\n",
    "            Tags: #tag1 #tag2 #tag3 #tag4 #tag5\\n \\\n",
    "        List of reviews: \\n\"\n",
    "    \n",
    "    def build_summary(self, review_qty=50, model='gpt-4'):\n",
    "        results = pd.DataFrame(columns=['category', 'product', 'prompt', 'reviews', 'review_qty', 'token_qty', 'response'])\n",
    "\n",
    "        for row, qty in self.reviews[['product_category', 'product_title']].value_counts()[:10].items():\n",
    "            try:\n",
    "                print(row[0], row[1], qty)\n",
    "                category = row[0]\n",
    "                product = row[1]\n",
    "\n",
    "                product_reviews = self.reviews[(self.reviews['product_category'] == category) & (self.reviews['product_title'] == product)][:review_qty]\n",
    "                \n",
    "                reviews = '\\n'.join(product_reviews['review_body'])\n",
    "                prompt = self.get_prompt(product)\n",
    "\n",
    "                message_prompt=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{prompt + reviews}:{product_reviews['review_body']}\"}]\n",
    "                \n",
    "                token_qty = num_tokens_from_messages(message_prompt, model=model)\n",
    "                print('tokens: ', token_qty)\n",
    "\n",
    "                chat_completion = openai.ChatCompletion.create(model=model, messages=message_prompt, ssl_check=False)\n",
    "                response = chat_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "                results = results.append({'category': category, 'product': product, 'prompt': prompt, 'reviews': reviews, 'review_qty':len(product_reviews), 'token_qty': token_qty, 'response': response}, ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print('error processing: ', row[0], row[1], qty, e)\n",
    "                pass\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "utl = Utils()\n",
    "utl.load_reviews('reviews_aws_sample.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home Entertainment Google Chromecast HDMI Streaming Media Player 1656\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "tokens:  843\n",
      "error processing:  Home Entertainment Google Chromecast HDMI Streaming Media Player 1656 Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)')))\n",
      "PC Kindle Fire HDX 7\", HDX Display (Previous Generation - 3rd) 1415\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "tokens:  686\n",
      "error processing:  PC Kindle Fire HDX 7\", HDX Display (Previous Generation - 3rd) 1415 Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)')))\n",
      "PC Fire HD 7, 7\" HD Display, Wi-Fi, 8 GB 1353\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "tokens:  540\n",
      "error processing:  PC Fire HD 7, 7\" HD Display, Wi-Fi, 8 GB 1353 Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)')))\n",
      "Electronics Panasonic ErgoFit In-Ear Earbud Headphone 1128\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "tokens:  627\n",
      "error processing:  Electronics Panasonic ErgoFit In-Ear Earbud Headphone 1128 Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)')))\n",
      "Toys Cards Against Humanity 1111\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "tokens:  519\n",
      "error processing:  Toys Cards Against Humanity 1111 Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)')))\n",
      "PC Kindle Fire (Previous Generation - 1st) 1091\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "tokens:  999\n",
      "error processing:  PC Kindle Fire (Previous Generation - 1st) 1091 Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)')))\n",
      "PC Kindle Paperwhite, 6\" High-Resolution Display (212 ppi) with Built-in Light, Wi-Fi 1086\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "tokens:  494\n",
      "error processing:  PC Kindle Paperwhite, 6\" High-Resolution Display (212 ppi) with Built-in Light, Wi-Fi 1086 Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)')))\n",
      "PC SanDisk Ultra microSDHC Card Plus Adapter 1018\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "tokens:  912\n",
      "error processing:  PC SanDisk Ultra microSDHC Card Plus Adapter 1018 Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)')))\n",
      "PC Fire HD 6 966\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "tokens:  605\n",
      "error processing:  PC Fire HD 6 966 Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)')))\n",
      "PC Kindle Fire HD 7\", Dolby Audio, Dual-Band Wi-Fi 897\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "tokens:  1127\n",
      "error processing:  PC Kindle Fire HD 7\", Dolby Audio, Dual-Band Wi-Fi 897 Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)')))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>prompt</th>\n",
       "      <th>reviews</th>\n",
       "      <th>review_qty</th>\n",
       "      <th>token_qty</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category, product, prompt, reviews, review_qty, token_qty, response]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = utl.build_summary(8, 'gpt-4')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(reviews_path + 'results_gpt4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Timex Women's Easy Reader Leather Strap Watch\n",
      "Summary: I bought this watch for my elderly mom and she loved it. The wide variety of materials and colors made it difficult to choose but I'm happy with the great color and dimensions of this watch. The oversize face is great and while the band is a bit stiff, I'm happy with how it looks. It's easy to read, but it does run slow and it's a bit tricky to reset the time. The indigo light is great for nighttime. However, the leather band started losing color and fading within a couple of months and getting it wet will temporarily stop it from working. Overall, it's a good and affordable watch, but think twice before buying it with a particular band.\n",
      "Tags: #ElderlyMom #ColorVariety #OversizedFace #FadingLeatherBand #RunsSlow\n"
     ]
    }
   ],
   "source": [
    "category = 'Watches'\n",
    "product = 'Timex Women\\'s Easy Reader Leather Strap Watch'\n",
    "\n",
    "product_reviews = utl.reviews[(utl.reviews['product_category'] == category) & (utl.reviews['product_title'] == product)]\n",
    "\n",
    "prompt = utl.get_prompt(product) + '\\n'.join(product_reviews['review_body'][:])\n",
    "\n",
    "message_prompt=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{prompt}:{product_reviews['review_body']}\"}]\n",
    "\n",
    "#\"gpt-3.5-turbo\"\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo-1106\", messages=message_prompt)\n",
    "\n",
    "print(chat_completion[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Timex Women's Easy Reader Leather Strap Watch\n",
      "Summary: The Timex Women's Easy Reader watch seems to be a hit among many for its oversized face, making it easy to read even without glasses - a feature greatly appreciated especially by older folks. Its Indigo light feature also adds to the ease of reading in the dark. The watch offers a variety in band materials, colors, and sizes which gives room for personal preference. Despite its slightly heavy feel and stiff band that takes a while to soften and mold to the wrist, the aesthetic appeal of the watch still shines through. However, there are some significant drawbacks to take into consideration. The watch seems to have a reputation for running slow and the time resetting function appears a bit tricky. Attention needs to be paid to the durability of the band as well, as it may show noticeable fading after extended use. The watch also may not perform well when in contact with water.      \n",
      "Tags: #LargeDial #AestheticAppeal #QuestionableDurability #NotWaterResistant #RunsSlow\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product[['review_body']].to_csv('D:/Disco/Data/datasets/amazon_us_reviews/reviews_aws_product.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
