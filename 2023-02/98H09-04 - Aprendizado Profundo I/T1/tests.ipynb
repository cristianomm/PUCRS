{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MLP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP.Model(MLP.LossFunction.MSE, MLP.Optimizer.ADAM, MLP.Regularizer.L2)\n",
    "\n",
    "model.add(MLP.Layer(MLP.LayerType.FLATTEN, (1,4), MLP.ActivationFunction.RELU, MLP.Initializer.HE))\n",
    "model.add(MLP.Layer(MLP.LayerType.DENSE, (1,3), MLP.ActivationFunction.RELU, MLP.Initializer.UNIFORM))\n",
    "model.add(MLP.Layer(MLP.LayerType.DENSE, (1,2), MLP.ActivationFunction.SOFTMAX, MLP.Initializer.NORMAL))\n",
    "\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].units[0].weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ActivationFunction' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\10087940\\Documents\\GitHub\\PUCRS\\2023-02\\98H09-04 - Aprendizado Profundo I\\T1\\tests.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/10087940/Documents/GitHub/PUCRS/2023-02/98H09-04%20-%20Aprendizado%20Profundo%20I/T1/tests.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m10\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m0.01\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\10087940\\Documents\\GitHub\\PUCRS\\2023-02\\98H09-04 - Aprendizado Profundo I\\T1\\MLP.py:196\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x_train, y_train, epochs, batch_size, learning_rate)\u001b[0m\n\u001b[0;32m    193\u001b[0m x_batch \u001b[39m=\u001b[39m x_train[start:end]\n\u001b[0;32m    194\u001b[0m y_batch \u001b[39m=\u001b[39m y_train[start:end]\n\u001b[1;32m--> 196\u001b[0m y_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__forward(x_batch)\n\u001b[0;32m    198\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_function \u001b[39m==\u001b[39m LossFunction\u001b[39m.\u001b[39mBCE:\n\u001b[0;32m    199\u001b[0m     loss \u001b[39m=\u001b[39m LossFunctions\u001b[39m.\u001b[39mbce(y_batch, y_hat)\n",
      "File \u001b[1;32mc:\\Users\\10087940\\Documents\\GitHub\\PUCRS\\2023-02\\98H09-04 - Aprendizado Profundo I\\T1\\MLP.py:217\u001b[0m, in \u001b[0;36mModel.__forward\u001b[1;34m(self, x_batch)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[39mfor\u001b[39;00m neuron \u001b[39min\u001b[39;00m layer\u001b[39m.\u001b[39munits:\n\u001b[0;32m    216\u001b[0m             \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m--> 217\u001b[0m                 neuron\u001b[39m.\u001b[39;49mcompute(value)\n\u001b[0;32m    218\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[39mfor\u001b[39;00m neuron \u001b[39min\u001b[39;00m layer\u001b[39m.\u001b[39munits:\n",
      "File \u001b[1;32mc:\\Users\\10087940\\Documents\\GitHub\\PUCRS\\2023-02\\98H09-04 - Aprendizado Profundo I\\T1\\MLP.py:174\u001b[0m, in \u001b[0;36mNeuron.compute\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(np\u001b[39m.\u001b[39;49mdot(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights) \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n\u001b[0;32m    175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ActivationFunction' object is not callable"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, 10, 100, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1 = (1,2)\n",
    "shape2 = (1,4)\n",
    "weights = np.random.randn(shape2[0], shape2[1]) * np.sqrt(2 / shape1[1])\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in enumerate(shape):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(-0.01, 0.01, (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones_like((1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
