{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting empyrical\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "     ---------------------------------------- 0.0/52.8 kB ? eta -:--:--\n",
      "     -------------- ----------------------- 20.5/52.8 kB 320.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 51.2/52.8 kB 518.5 kB/s eta 0:00:01\n",
      "     -------------------------------------- 52.8/52.8 kB 538.6 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from empyrical) (1.26.1)\n",
      "Requirement already satisfied: pandas>=0.16.1 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from empyrical) (2.2.3)\n",
      "Requirement already satisfied: scipy>=0.15.1 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from empyrical) (1.11.3)\n",
      "Collecting pandas-datareader>=0.2 (from empyrical)\n",
      "  Obtaining dependency information for pandas-datareader>=0.2 from https://files.pythonhosted.org/packages/3f/16/56c9d648b503619ebe96f726b5f642b68e299b34162ed2d6faa9d7966b7d/pandas_datareader-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading pandas_datareader-0.10.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from pandas>=0.16.1->empyrical) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from pandas>=0.16.1->empyrical) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from pandas>=0.16.1->empyrical) (2023.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from pandas-datareader>=0.2->empyrical) (5.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from pandas-datareader>=0.2->empyrical) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.16.1->empyrical) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical) (2023.7.22)\n",
      "Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "   ---------------------------------------- 0.0/109.5 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 71.7/109.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 109.5/109.5 kB 2.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: empyrical\n",
      "  Building wheel for empyrical (setup.py): started\n",
      "  Building wheel for empyrical (setup.py): finished with status 'done'\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39796 sha256=84ef9019d1d93ec74db8652081ffc4c46bd135803bad0413205ab1521a477565\n",
      "  Stored in directory: c:\\users\\crist\\appdata\\local\\pip\\cache\\wheels\\0e\\2e\\f2\\d6d2d9a1eb8fbbd9949bb5d4c00f753e3b74e5bd7ed10b1d36\n",
      "Successfully built empyrical\n",
      "Installing collected packages: pandas-datareader, empyrical\n",
      "Successfully installed empyrical-0.5.5 pandas-datareader-0.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lama-cpp-python (c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lama-cpp-python (c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crist\\.conda\\envs\\deep-learning\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#!pip install stable_baselines3\n",
    "#!pip install yfinance yahoo_fin pandas\n",
    "#!pip install pyarrow pandas --upgrade\n",
    "!pip install empyrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import empyrical as ep\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/Disco/Data/MT5/D1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ALOS3', 'ABEV3', 'ASAI3', 'AZUL4', 'AZZA3', 'B3SA3', 'BBSE3', 'BBDC4',\n",
       "       'BBAS3', 'BRAV3', 'BRFS3', 'BPAC11', 'CMIG4', 'CPLE6', 'CSAN3', 'CYRE3',\n",
       "       'ELET3', 'EMBR3', 'ENGI11', 'EQTL3', 'GGBR4', 'NTCO3', 'HAPV3', 'HYPE3',\n",
       "       'ITSA4', 'ITUB4', 'JBSS3', 'KLBN11', 'RENT3', 'LREN3', 'MGLU3', 'MRVE3',\n",
       "       'MULT3', 'PETR3', 'PETR4', 'PRIO3', 'RADL3', 'RDOR3', 'RAIL3', 'SBSP3',\n",
       "       'CSNA3', 'SUZB3', 'VIVT3', 'TIMS3', 'TOTS3', 'UGPA3', 'USIM5', 'VALE3',\n",
       "       'VBBR3', 'WEGE3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = pd.read_csv('IBXLDia_29-11-24.csv', sep=';', encoding='UTF-8', skiprows=1)['codigo'].index\n",
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2023-10-25    23.28\n",
       "2023-10-26    23.66\n",
       "2023-10-27    23.15\n",
       "2023-10-30    22.60\n",
       "2023-10-31    22.97\n",
       "              ...  \n",
       "2024-10-14    22.43\n",
       "2024-10-15    22.49\n",
       "2024-10-16    22.43\n",
       "2024-10-17    22.51\n",
       "2024-10-18    22.22\n",
       "Name: close, Length: 248, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in symbols:\n",
    "    data = pd.read_parquet(f'{path}{symbols[0]}.parquet')\n",
    "    data['return'] = ep.ann\n",
    "    data['vol'] = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PortfolioEnv(gym.Env):\n",
    "    def __init__(self, data, max_assets=4):\n",
    "        super(PortfolioEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.max_assets = max_assets\n",
    "        self.num_assets = data.shape[1] - 2  # Supondo que as 2 primeiras colunas são retorno e volatilidade\n",
    "        self.current_step = 0\n",
    "        # Ação: selecionar até max_assets ativos\n",
    "        self.action_space = spaces.MultiBinary(self.num_assets)\n",
    "        # Estado: retorno, volatilidade e portfólio atual\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, \n",
    "                                            shape=(self.num_assets * 2 + self.num_assets,), \n",
    "                                            dtype=np.float32)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.portfolio = np.zeros(self.num_assets)\n",
    "        return self._get_obs()\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        returns = self.data.iloc[self.current_step, :self.num_assets].values\n",
    "        volatility = self.data.iloc[self.current_step, self.num_assets:2*self.num_assets].values\n",
    "        portfolio = self.portfolio\n",
    "        return np.concatenate([returns, volatility, portfolio])\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Aplicar ação com restrição de max_assets\n",
    "        if np.sum(action) > self.max_assets:\n",
    "            reward = -10  # Penalidade por violar a restrição\n",
    "            done = True\n",
    "            return self._get_obs(), reward, done, {}\n",
    "        self.portfolio = action\n",
    "        # Calcular retorno do portfólio\n",
    "        returns = self.data.iloc[self.current_step, :self.num_assets].values\n",
    "        portfolio_return = np.dot(self.portfolio, returns)\n",
    "        reward = portfolio_return  # Objetivo de maximizar o retorno\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        return self._get_obs(), reward, done, {}\n",
    "    \n",
    "# Carregar e pré-processar os dados\n",
    "# data deve ser um DataFrame onde as primeiras 50 colunas são retornos e as próximas 50 são volatilidades\n",
    "data = pd.read_csv('dados_portfolio.csv')  # Substitua pelo caminho dos seus dados\n",
    "\n",
    "env = PortfolioEnv(data)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=100000)\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save(\"ppo_portfolio\")\n",
    "\n",
    "# Carregar o modelo\n",
    "# model = PPO.load(\"ppo_portfolio\")\n",
    "\n",
    "# Testar o modelo\n",
    "obs = env.reset()\n",
    "for _ in range(len(data)):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/Disco/Data/MT5/D1/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin import stock_info as si\n",
    "\n",
    "# Obter os ativos mais ativos do dia\n",
    "most_active = si.get_day_most_active()\n",
    "\n",
    "# Selecionar os top 50 ativos\n",
    "top_50 = most_active.head(50)\n",
    "\n",
    "# Exibir a lista de ativos\n",
    "print(top_50[['Symbol', 'Volume']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
